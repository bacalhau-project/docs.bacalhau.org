"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"documentationSidebar":[{"type":"link","label":"Home","href":"/","docId":"intro","unlisted":false},{"type":"category","label":"Getting Started","collapsed":false,"items":[{"type":"link","label":"Architecture","href":"/getting-started/architecture","docId":"getting-started/architecture","unlisted":false},{"type":"link","label":"Installation","href":"/getting-started/installation","docId":"getting-started/installation","unlisted":false},{"type":"link","label":"Onboard Docker Workload","href":"/getting-started/docker-workload-onboarding","docId":"getting-started/docker-workload-onboarding","unlisted":false},{"type":"link","label":"Onboard WebAssembly Workload","href":"/getting-started/wasm-workload-onboarding","docId":"getting-started/wasm-workload-onboarding","unlisted":false},{"type":"link","label":"Specifying Hardware Requirements","href":"/getting-started/resources","docId":"getting-started/resources","unlisted":false}],"collapsible":true,"href":"/getting-started"},{"type":"category","label":"Examples","collapsed":true,"items":[{"type":"category","label":"Case Studies","items":[{"type":"link","label":"DuckDB","href":"/examples/case-studies/duckdb-log-processing/","docId":"examples/case-studies/duckdb-log-processing/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/case-studies"},{"type":"category","label":"Workload Onboarding","items":[{"type":"link","label":"Bacalhau Docker Image","href":"/examples/workload-onboarding/bacalhau-docker-image/","docId":"examples/workload-onboarding/bacalhau-docker-image/index","unlisted":false},{"type":"link","label":"Reading-From-Multiple-S3-Buckets","href":"/examples/workload-onboarding/Reading-From-Multiple-S3-Buckets/","docId":"examples/workload-onboarding/Reading-From-Multiple-S3-Buckets/index","unlisted":false},{"type":"link","label":"Running-Jupyter-Notebook","href":"/examples/workload-onboarding/Running-Jupyter-Notebook/","docId":"examples/workload-onboarding/Running-Jupyter-Notebook/index","unlisted":false},{"type":"link","label":"Prolog Script","href":"/examples/workload-onboarding/Prolog-Hello-World/","docId":"examples/workload-onboarding/Prolog-Hello-World/index","unlisted":false},{"type":"link","label":"Python Custom Container","href":"/examples/workload-onboarding/Python-Custom-Container/","docId":"examples/workload-onboarding/Python-Custom-Container/index","unlisted":false},{"type":"link","label":"Python Pandas","href":"/examples/workload-onboarding/python-pandas/","docId":"examples/workload-onboarding/python-pandas/index","unlisted":false},{"type":"link","label":"R Custom Container","href":"/examples/workload-onboarding/r-custom-docker-prophet/","docId":"examples/workload-onboarding/r-custom-docker-prophet/index","unlisted":false},{"type":"link","label":"R Script","href":"/examples/workload-onboarding/r-hello-world/","docId":"examples/workload-onboarding/r-hello-world/index","unlisted":false},{"type":"link","label":"CUDA","href":"/examples/workload-onboarding/CUDA/","docId":"examples/workload-onboarding/CUDA/index","unlisted":false},{"type":"link","label":"Rust WASM","href":"/examples/workload-onboarding/rust-wasm/","docId":"examples/workload-onboarding/rust-wasm/index","unlisted":false},{"type":"link","label":"Sparkov Data Generation","href":"/examples/workload-onboarding/Sparkov-Data-Generation/","docId":"examples/workload-onboarding/Sparkov-Data-Generation/index","unlisted":false},{"type":"link","label":"Custom Containers","href":"/examples/workload-onboarding/custom-containers/","docId":"examples/workload-onboarding/custom-containers/index","unlisted":false},{"type":"link","label":"CUDA","href":"/examples/workload-onboarding/CUDA/","docId":"examples/workload-onboarding/CUDA/index","unlisted":false},{"type":"link","label":"Python File","href":"/examples/workload-onboarding/trivial-python/","docId":"examples/workload-onboarding/trivial-python/index","unlisted":false},{"type":"link","label":"Scripting Bacalhau with Python","href":"/examples/workload-onboarding/python-script/","docId":"examples/workload-onboarding/python-script/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/workload-onboarding"},{"type":"category","label":"Data Engineering","items":[{"type":"link","label":"Ethereum Blockchain Analysis","href":"/examples/data-engineering/blockchain-etl/","docId":"examples/data-engineering/blockchain-etl/index","unlisted":false},{"type":"link","label":"csv-to-avro-or-parquet","href":"/examples/data-engineering/csv-to-avro-or-parquet/","docId":"examples/data-engineering/csv-to-avro-or-parquet/index","unlisted":false},{"type":"link","label":"DuckDB","href":"/examples/data-engineering/DuckDB/","docId":"examples/data-engineering/DuckDB/index","unlisted":false},{"type":"link","label":"Simple Image Processing","href":"/examples/data-engineering/image-processing/","docId":"examples/data-engineering/image-processing/index","unlisted":false},{"type":"link","label":"Oceanography - Data Conversion","href":"/examples/data-engineering/oceanography-conversion/","docId":"examples/data-engineering/oceanography-conversion/index","unlisted":false},{"type":"link","label":"Video Processing","href":"/examples/data-engineering/simple-parallel-workloads/","docId":"examples/data-engineering/simple-parallel-workloads/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/data-engineering"},{"type":"category","label":"Model Inference","items":[{"type":"link","label":"Huggingface-Model-Inference","href":"/examples/model-inference/Huggingface-Model-Inference/","docId":"examples/model-inference/Huggingface-Model-Inference/index","unlisted":false},{"type":"link","label":"Object Detection - YOLOv5","href":"/examples/model-inference/object-detection-yolo5/","docId":"examples/model-inference/object-detection-yolo5/index","unlisted":false},{"type":"link","label":"S3-Model-Inference","href":"/examples/model-inference/S3-Model-Inference/","docId":"examples/model-inference/S3-Model-Inference/index","unlisted":false},{"type":"link","label":"Stable Diffusion -CKPT","href":"/examples/model-inference/Stable-Diffusion-CKPT-Inference/","docId":"examples/model-inference/Stable-Diffusion-CKPT-Inference/index","unlisted":false},{"type":"link","label":"Stable Diffusion - CPU","href":"/examples/model-inference/stable-diffusion-cpu/","docId":"examples/model-inference/stable-diffusion-cpu/index","unlisted":false},{"type":"link","label":"Stable Diffusion - GPU","href":"/examples/model-inference/stable-diffusion-gpu/","docId":"examples/model-inference/stable-diffusion-gpu/index","unlisted":false},{"type":"link","label":"StyleGAN3","href":"/examples/model-inference/StyleGAN3/","docId":"examples/model-inference/StyleGAN3/index","unlisted":false},{"type":"link","label":"EasyOCR","href":"/examples/model-inference/EasyOCR/","docId":"examples/model-inference/EasyOCR/index","unlisted":false},{"type":"link","label":"Speech Recognition using Whisper","href":"/examples/model-inference/Openai-Whisper/","docId":"examples/model-inference/Openai-Whisper/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/model-inference"},{"type":"category","label":"Model Training","items":[{"type":"link","label":"Stable-Diffusion-Dreambooth","href":"/examples/model-training/Stable-Diffusion-Dreambooth/","docId":"examples/model-training/Stable-Diffusion-Dreambooth/index","unlisted":false},{"type":"link","label":"Training-Pytorch-Model","href":"/examples/model-training/Training-Pytorch-Model/","docId":"examples/model-training/Training-Pytorch-Model/index","unlisted":false},{"type":"link","label":"Training-Tensorflow-Model","href":"/examples/model-training/Training-Tensorflow-Model/","docId":"examples/model-training/Training-Tensorflow-Model/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/model-training"},{"type":"category","label":"Molecular Dynamics","items":[{"type":"link","label":"BIDS","href":"/examples/molecular-dynamics/BIDS/","docId":"examples/molecular-dynamics/BIDS/index","unlisted":false},{"type":"link","label":"Coresets On Bacalhau","href":"/examples/molecular-dynamics/Coreset/","docId":"examples/molecular-dynamics/Coreset/index","unlisted":false},{"type":"link","label":"Genomics","href":"/examples/molecular-dynamics/Genomics/","docId":"examples/molecular-dynamics/Genomics/index","unlisted":false},{"type":"link","label":"Gromacs","href":"/examples/molecular-dynamics/Gromacs/","docId":"examples/molecular-dynamics/Gromacs/index","unlisted":false},{"type":"link","label":"Simulation with OpenMM","href":"/examples/molecular-dynamics/openmm/","docId":"examples/molecular-dynamics/openmm/index","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/molecular-dynamics"}],"collapsible":true,"href":"/examples"},{"type":"category","label":"Topic Guides","collapsed":true,"items":[{"type":"link","label":"Job types","href":"/topic-guides/job-types","docId":"topic-guides/job-types","unlisted":false}],"collapsible":true,"href":"/topic-guides/"},{"type":"category","label":"Data Ingestion","collapsed":true,"items":[{"type":"link","label":"From A URL","href":"/data-ingestion/from-url","docId":"data-ingestion/from-url","unlisted":false},{"type":"link","label":"Pinning data","href":"/data-ingestion/pin","docId":"data-ingestion/pin","unlisted":false},{"type":"link","label":"Running a job over S3 data ","href":"/data-ingestion/s3","docId":"data-ingestion/s3","unlisted":false}],"collapsible":true,"href":"/data-ingestion"},{"type":"category","label":"Process","collapsed":true,"items":[{"type":"link","label":"GPU Workloads","href":"/next-steps/gpu","docId":"next-steps/gpu","unlisted":false},{"type":"link","label":"Networking","href":"/next-steps/networking","docId":"next-steps/networking","unlisted":false},{"type":"link","label":"Private Cluster","href":"/next-steps/private-cluster","docId":"next-steps/private-cluster","unlisted":false},{"type":"link","label":"Update Checking","href":"/next-steps/update-checks","docId":"next-steps/update-checks","unlisted":false}],"collapsible":true,"href":"/process"},{"type":"category","label":"Running a Node","collapsed":true,"items":[{"type":"link","label":"Quick Start","href":"/running-node/quick-start","docId":"running-node/quick-start","unlisted":false},{"type":"link","label":"Quick Start Using Docker","href":"/running-node/quick-start-docker","docId":"running-node/quick-start-docker","unlisted":false},{"type":"link","label":"Networking","href":"/running-node/networking","docId":"running-node/networking","unlisted":false},{"type":"link","label":"Storage Providers","href":"/running-node/storage-providers","docId":"running-node/storage-providers","unlisted":false},{"type":"link","label":"Job Selection Policy","href":"/running-node/job-selection","docId":"running-node/job-selection","unlisted":false},{"type":"link","label":"Resource Limits","href":"/running-node/resource-limits","docId":"running-node/resource-limits","unlisted":false},{"type":"link","label":"Timeouts","href":"/running-node/timeouts","docId":"running-node/timeouts","unlisted":false},{"type":"link","label":"Test Network Locally","href":"/running-node/test-network","docId":"running-node/test-network","unlisted":false},{"type":"link","label":"GPU Support","href":"/running-node/gpu","docId":"running-node/gpu","unlisted":false},{"type":"link","label":"Configuring node persistence","href":"/running-node/persistence","docId":"running-node/persistence","unlisted":false},{"type":"link","label":"Configuring TLS","href":"/running-node/configuring-tls","docId":"running-node/configuring-tls","unlisted":false},{"type":"link","label":"Windows Support","href":"/running-node/windows-support","docId":"running-node/windows-support","unlisted":false},{"type":"link","label":"Observability","href":"/running-node/observability","docId":"running-node/observability","unlisted":false},{"type":"link","label":"Configuration","href":"/running-node/configuration","docId":"running-node/configuration","unlisted":false}],"collapsible":true,"href":"/running-node"},{"type":"category","label":"References","collapsed":true,"items":[{"type":"category","label":"API","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Agent","href":"/references/api/agent","docId":"references/api/agent","unlisted":false},{"type":"link","label":"Jobs","href":"/references/api/jobs","docId":"references/api/jobs","unlisted":false},{"type":"link","label":"Nodes","href":"/references/api/nodes","docId":"references/api/nodes","unlisted":false}],"href":"/references/api/"},{"type":"category","label":"Commands (CLI)","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"agent","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"alive","href":"/references/cli/agent/alive/","docId":"references/cli/agent/alive/index","unlisted":false},{"type":"link","label":"node","href":"/references/cli/agent/node/","docId":"references/cli/agent/node/index","unlisted":false},{"type":"link","label":"version","href":"/references/cli/agent/version/","docId":"references/cli/agent/version/index","unlisted":false}],"href":"/references/cli/agent/"},{"type":"category","label":"job","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"describe","href":"/references/cli/job/describe/","docId":"references/cli/job/describe/index","unlisted":false},{"type":"link","label":"executions","href":"/references/cli/job/executions/","docId":"references/cli/job/executions/index","unlisted":false},{"type":"link","label":"history","href":"/references/cli/job/history/","docId":"references/cli/job/history/index","unlisted":false},{"type":"link","label":"list","href":"/references/cli/job/list/","docId":"references/cli/job/list/index","unlisted":false},{"type":"link","label":"logs","href":"/references/cli/job/logs/","docId":"references/cli/job/logs/index","unlisted":false},{"type":"link","label":"run","href":"/references/cli/job/run/","docId":"references/cli/job/run/index","unlisted":false},{"type":"link","label":"stop","href":"/references/cli/job/stop/","docId":"references/cli/job/stop/index","unlisted":false}],"href":"/references/cli/job/"},{"type":"category","label":"node","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"describe","href":"/references/cli/node/describe/","docId":"references/cli/node/describe/index","unlisted":false},{"type":"link","label":"list","href":"/references/cli/node/list/","docId":"references/cli/node/list/index","unlisted":false}],"href":"/references/cli/node/"}],"href":"/references/cli/"},{"type":"category","label":"Job Specification","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Constraint","href":"/references/job-specification/constraint","docId":"references/job-specification/constraint","unlisted":false},{"type":"link","label":"InputSource","href":"/references/job-specification/input-source","docId":"references/job-specification/input-source","unlisted":false},{"type":"link","label":"Label","href":"/references/job-specification/label","docId":"references/job-specification/label","unlisted":false},{"type":"link","label":"Meta","href":"/references/job-specification/meta","docId":"references/job-specification/meta","unlisted":false},{"type":"link","label":"Network","href":"/references/job-specification/network","docId":"references/job-specification/network","unlisted":false},{"type":"link","label":"Resources","href":"/references/job-specification/resources","docId":"references/job-specification/resources","unlisted":false},{"type":"link","label":"ResultPath","href":"/references/job-specification/result-path","docId":"references/job-specification/result-path","unlisted":false},{"type":"link","label":"SpecConfig","href":"/references/job-specification/spec-config","docId":"references/job-specification/spec-config","unlisted":false},{"type":"link","label":"State","href":"/references/job-specification/state","docId":"references/job-specification/state","unlisted":false},{"type":"link","label":"Task","href":"/references/job-specification/task","docId":"references/job-specification/task","unlisted":false},{"type":"link","label":"Timeouts","href":"/references/job-specification/timeouts","docId":"references/job-specification/timeouts","unlisted":false}],"href":"/references/job-specification/job"},{"type":"category","label":"Other Specifications","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Engines","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Docker","href":"/references/other-specifications/engines/docker","docId":"references/other-specifications/engines/docker","unlisted":false},{"type":"link","label":"Wasm","href":"/references/other-specifications/engines/wasm","docId":"references/other-specifications/engines/wasm","unlisted":false}],"href":"/category/engines"},{"type":"category","label":"Publishers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"IPFS","href":"/references/other-specifications/publishers/ipfs","docId":"references/other-specifications/publishers/ipfs","unlisted":false},{"type":"link","label":"S3","href":"/references/other-specifications/publishers/s3","docId":"references/other-specifications/publishers/s3","unlisted":false}],"href":"/category/publishers"},{"type":"category","label":"Sources","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"IPFS","href":"/references/other-specifications/sources/ipfs","docId":"references/other-specifications/sources/ipfs","unlisted":false},{"type":"link","label":"Local","href":"/references/other-specifications/sources/local","docId":"references/other-specifications/sources/local","unlisted":false},{"type":"link","label":"S3","href":"/references/other-specifications/sources/s3","docId":"references/other-specifications/sources/s3","unlisted":false},{"type":"link","label":"URL","href":"/references/other-specifications/sources/url","docId":"references/other-specifications/sources/url","unlisted":false}],"href":"/category/sources"}],"href":"/category/other-specifications"},{"type":"category","label":"SDK","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Bacalhau Python SDK","href":"/references/sdk/python-sdk","docId":"references/sdk/python-sdk","unlisted":false}],"href":"/category/sdk"}],"collapsible":true,"href":"/references"},{"type":"category","label":"FAQS","collapsed":true,"items":[{"type":"link","label":"Debugging Jobs","href":"/troubleshooting/debugging","docId":"troubleshooting/debugging","unlisted":false},{"type":"link","label":"FAQs","href":"/troubleshooting/faqs","docId":"troubleshooting/faqs","unlisted":false},{"type":"link","label":"CLI Reference","href":"/all-flags","docId":"all-flags","unlisted":false}],"collapsible":true,"href":"/troubleshooting"},{"type":"category","label":"Integration","collapsed":true,"items":[{"type":"link","label":"Apache Airflow","href":"/integration/apache-airflow","docId":"integration/apache-airflow","unlisted":false},{"type":"link","label":"Amplify","href":"/integration/amplify","docId":"integration/amplify","unlisted":false},{"type":"link","label":"Lilypad for Web3","href":"/integration/lilypad","docId":"integration/lilypad","unlisted":false},{"type":"link","label":"WebAssembly Observability","href":"/integration/wasm-observe","docId":"integration/wasm-observe","unlisted":false}],"collapsible":true,"href":"/integration"},{"type":"category","label":"Community","collapsed":true,"items":[{"type":"link","label":"Landscape","href":"/community/compute-landscape","docId":"community/compute-landscape","unlisted":false},{"type":"link","label":"Development","href":"/community/development","docId":"community/development","unlisted":false},{"type":"link","label":"Style Guide","href":"/community/style-guide","docId":"community/style-guide","unlisted":false},{"type":"link","label":"Ways to Contribute","href":"/community/ways-to-contribute","docId":"community/ways-to-contribute","unlisted":false}],"collapsible":true,"href":"/community"}]},"docs":{"all-flags":{"id":"all-flags","title":"CLI Commands","description":"The following commands refer to bacalhau cli version v1.0.3.","sidebar":"documentationSidebar"},"community/compute-landscape":{"id":"community/compute-landscape","title":"Compute Over Data - Landscape Analysis","description":"This page is an introduction to a landscape analysis of general-purpose compute frameworks.","sidebar":"documentationSidebar"},"community/development":{"id":"community/development","title":"Development","description":"You can run a stand-alone Bacalhau and IPFS network on your computer with the following guide.","sidebar":"documentationSidebar"},"community/social-media":{"id":"community/social-media","title":"Social Media","description":"Find Bacalhau on your favorite social media platform"},"community/style-guide":{"id":"community/style-guide","title":"Style Guide","description":"This guide explains things to keep in mind when writing for Bacalhau\u2019s documentation.","sidebar":"documentationSidebar"},"community/ways-to-contribute":{"id":"community/ways-to-contribute","title":"Ways to Contribute","description":"How to contribute to Bacalhau","sidebar":"documentationSidebar"},"data-ingestion/from-url":{"id":"data-ingestion/from-url","title":"Copy Data from a URL to a Public Storage","description":"To upload a file from a URL we will use the bacalhau docker run command.","sidebar":"documentationSidebar"},"data-ingestion/index":{"id":"data-ingestion/index","title":"index","description":""},"data-ingestion/pin":{"id":"data-ingestion/pin","title":"Pinning Data","description":"How to pin data to public storage","sidebar":"documentationSidebar"},"data-ingestion/s3":{"id":"data-ingestion/s3","title":"Running a Job over S3 data","description":"Here is a quick tutorial on how to copy Data from S3 to a public storage. In this tutorial, we will scrape all the links from a public AWS S3 buckets and then copy the data to IPFS using Bacalhau.","sidebar":"documentationSidebar"},"examples/case-studies/duckdb-log-processing/index":{"id":"examples/case-studies/duckdb-log-processing/index","title":"index","description":"DuckDB is an embedded SQL database tool that is designed to analyze data without external dependencies or state, that can be embedded locally on any machine.","sidebar":"documentationSidebar"},"examples/case-studies/index":{"id":"examples/case-studies/index","title":"index","description":""},"examples/data-engineering/blockchain-etl/index":{"id":"examples/data-engineering/blockchain-etl/index","title":"Ethereum Blockchain Analysis with Ethereum-ETL and Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/data-engineering/csv-to-avro-or-parquet/index":{"id":"examples/data-engineering/csv-to-avro-or-parquet/index","title":"Convert CSV To Parquet Or Avro","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/data-engineering/DuckDB/index":{"id":"examples/data-engineering/DuckDB/index","title":"Using Bacalhau with DuckDB","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/data-engineering/image-processing/index":{"id":"examples/data-engineering/image-processing/index","title":"Simple Image Processing","description":"How to process images stored in IPFS with Bacalhau","sidebar":"documentationSidebar"},"examples/data-engineering/index":{"id":"examples/data-engineering/index","title":"Data Engineering","description":"This directory contains examples relating to data engineering workloads."},"examples/data-engineering/oceanography-conversion/index":{"id":"examples/data-engineering/oceanography-conversion/index","title":"Oceanography - Data Conversion","description":"Oceanography data conversion with Bacalhau","sidebar":"documentationSidebar"},"examples/data-engineering/simple-parallel-workloads/index":{"id":"examples/data-engineering/simple-parallel-workloads/index","title":"Video Processing","description":"Parallel Video Resizing via File Sharding","sidebar":"documentationSidebar"},"examples/index":{"id":"examples/index","title":"Examples","description":"Bacalhau comes pre-loaded with exciting examples to showcase its abilities and help get you started."},"examples/model-inference/EasyOCR/index":{"id":"examples/model-inference/EasyOCR/index","title":"EasyOCR (Optical Character Recognition) on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/Huggingface-Model-Inference/index":{"id":"examples/model-inference/Huggingface-Model-Inference/index","title":"Running Inference on Dolly 2.0 Model with Hugging Face","description":"Open In Colab","sidebar":"documentationSidebar"},"examples/model-inference/index":{"id":"examples/model-inference/index","title":"Model Inference","description":"This directory contains examples relating to model inference workloads."},"examples/model-inference/object-detection-yolo5/index":{"id":"examples/model-inference/object-detection-yolo5/index","title":"Object Detection with YOLOv5 on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/Openai-Whisper/index":{"id":"examples/model-inference/Openai-Whisper/index","title":"Speech Recognition using Whisper","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/S3-Model-Inference/index":{"id":"examples/model-inference/S3-Model-Inference/index","title":"Running Inference on a Model stored on S3","description":"Open In Colab","sidebar":"documentationSidebar"},"examples/model-inference/Stable-Diffusion-CKPT-Inference/index":{"id":"examples/model-inference/Stable-Diffusion-CKPT-Inference/index","title":"Stable Diffusion Checkpoint Inference","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/stable-diffusion-cpu/index":{"id":"examples/model-inference/stable-diffusion-cpu/index","title":"Stable Diffusion on a CPU","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/stable-diffusion-gpu/index":{"id":"examples/model-inference/stable-diffusion-gpu/index","title":"Stable Diffusion on a GPU","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-inference/StyleGAN3/index":{"id":"examples/model-inference/StyleGAN3/index","title":"Generate Realistic Images using StyleGAN3 and Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-training/index":{"id":"examples/model-training/index","title":"Model Training","description":"This directory contains examples relating to model training workloads."},"examples/model-training/Stable-Diffusion-Dreambooth/index":{"id":"examples/model-training/Stable-Diffusion-Dreambooth/index","title":"Stable Diffusion Dreambooth (Finetuning)","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-training/Training-Pytorch-Model/index":{"id":"examples/model-training/Training-Pytorch-Model/index","title":"Training Pytorch Model with Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/model-training/Training-Tensorflow-Model/index":{"id":"examples/model-training/Training-Tensorflow-Model/index","title":"Training Tensorflow Model","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/molecular-dynamics/BIDS/index":{"id":"examples/molecular-dynamics/BIDS/index","title":"Running BIDS Apps on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/molecular-dynamics/Coreset/index":{"id":"examples/molecular-dynamics/Coreset/index","title":"Coresets On Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/molecular-dynamics/Genomics/index":{"id":"examples/molecular-dynamics/Genomics/index","title":"Running Genomics on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/molecular-dynamics/Gromacs/index":{"id":"examples/molecular-dynamics/Gromacs/index","title":"Gromacs","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/molecular-dynamics/index":{"id":"examples/molecular-dynamics/index","title":"Data Engineering","description":"This directory contains examples relating to molecular dynamics workloads."},"examples/molecular-dynamics/openmm/index":{"id":"examples/molecular-dynamics/openmm/index","title":"Molecular Simulation with OpenMM and Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/bacalhau-docker-image/index":{"id":"examples/workload-onboarding/bacalhau-docker-image/index","title":"Bacalhau Docker Image","description":"How to use the Bacalhau Docker image","sidebar":"documentationSidebar"},"examples/workload-onboarding/CUDA/index":{"id":"examples/workload-onboarding/CUDA/index","title":"Run CUDA programs on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/custom-containers/index":{"id":"examples/workload-onboarding/custom-containers/index","title":"How To Work With Custom Containers in Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/index":{"id":"examples/workload-onboarding/index","title":"How To Work With Bacalhau","description":"This directory contains examples relating to performing common tasks with Bacalhau."},"examples/workload-onboarding/Prolog-Hello-World/index":{"id":"examples/workload-onboarding/Prolog-Hello-World/index","title":"Running a Prolog Script","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/Python-Custom-Container/index":{"id":"examples/workload-onboarding/Python-Custom-Container/index","title":"Building and Running Custom Python  Container","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/python-pandas/index":{"id":"examples/workload-onboarding/python-pandas/index","title":"Running Pandas on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/python-script/index":{"id":"examples/workload-onboarding/python-script/index","title":"Scripting Bacalhau with Python","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/r-custom-docker-prophet/index":{"id":"examples/workload-onboarding/r-custom-docker-prophet/index","title":"Building and Running your Custom R Containers on Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/r-hello-world/index":{"id":"examples/workload-onboarding/r-hello-world/index","title":"Running a Simple R Script in Bacalhau","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/Reading-From-Multiple-S3-Buckets/index":{"id":"examples/workload-onboarding/Reading-From-Multiple-S3-Buckets/index","title":"Reading Data from Multiple S3 Buckets using Bacalhau","description":"Open In Colab","sidebar":"documentationSidebar"},"examples/workload-onboarding/Running-Jupyter-Notebook/index":{"id":"examples/workload-onboarding/Running-Jupyter-Notebook/index","title":"Running Jupyter Notebooks on bacalhau","description":"Open In Colab","sidebar":"documentationSidebar"},"examples/workload-onboarding/rust-wasm/index":{"id":"examples/workload-onboarding/rust-wasm/index","title":"Running Rust programs as WebAssembly (WASM)","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/Sparkov-Data-Generation/index":{"id":"examples/workload-onboarding/Sparkov-Data-Generation/index","title":"Generate Synthetic Data using Sparkov Data Generation technique","description":"stars - badge-generator","sidebar":"documentationSidebar"},"examples/workload-onboarding/trivial-python/index":{"id":"examples/workload-onboarding/trivial-python/index","title":"Running a Python Script","description":"How to run a Python file hosted on Bacalhau","sidebar":"documentationSidebar"},"getting-started/architecture":{"id":"getting-started/architecture","title":"Architecture","description":"Bacalhau is a peer-to-peer network of nodes that allows for decentralized communication between computers. There are two nodes types in the network:","sidebar":"documentationSidebar"},"getting-started/docker-workload-onboarding":{"id":"getting-started/docker-workload-onboarding","title":"Onboarding Your Docker Workloads","description":"How to use docker containers with Bacalhau","sidebar":"documentationSidebar"},"getting-started/index":{"id":"getting-started/index","title":"index","description":""},"getting-started/installation":{"id":"getting-started/installation","title":"Getting Started with Bacalhau","description":"In this tutorial, you\'ll learn how to install and run a job with the Bacalhau client using the Bacalhau CLI or Docker.","sidebar":"documentationSidebar"},"getting-started/resources":{"id":"getting-started/resources","title":"Specifying Hardware Requirements","description":"Not all jobs are created equal. Some jobs require more resources than others or have specific hardware requirements like GPUs. This page describes how to specify hardware requirements for your job.","sidebar":"documentationSidebar"},"getting-started/wasm-workload-onboarding":{"id":"getting-started/wasm-workload-onboarding","title":"Onboarding Your WebAssembly Workloads","description":"Bacalhau supports running programs that are compiled to WebAssembly (WASM). With the Bacalhau client, you can upload WASM programs, retrieve data from public storage, read and write data, receive program arguments, and access environment variables.","sidebar":"documentationSidebar"},"integration/amplify":{"id":"integration/amplify","title":"Bacalhau Amplify","description":"Bacalhau Amplify is a tool for automatically explaining, enriching, and enhancing your data.","sidebar":"documentationSidebar"},"integration/apache-airflow":{"id":"integration/apache-airflow","title":"Apache Airflow Provider for Bacalhau","description":"This is bacalhau-airflow, a Python package that integrates Bacalhau with Apache Airflow.","sidebar":"documentationSidebar"},"integration/index":{"id":"integration/index","title":"index","description":""},"integration/lilypad":{"id":"integration/lilypad","title":"\ud83c\udf43 What is Lilypad?","description":"Lilypad is a distributed compute network for web3 based on Bacalhau. It currently enables the running of Bacalhau jobs from smart contracts.","sidebar":"documentationSidebar"},"integration/wasm-observe":{"id":"integration/wasm-observe","title":"Observability for WebAssembly Workloads in Bacalhau","description":"Gain deeper insights into the WebAssembly (Wasm) jobs running on Bacalhau compute nodes using the","sidebar":"documentationSidebar"},"intro":{"id":"intro","title":"Home","description":"Bacalhau is a platform for fast, cost efficient, and secure computation by running jobs where the data is generated and stored. With Bacalhau, you can streamline your existing workflows without the need of extensive rewriting by running  arbitrary Docker containers and WebAssembly (wasm) images as tasks. This architecture is also referred to as Compute Over Data (or CoD). Bacalhau was coined from the Portuguese word for salted Cod fish.","sidebar":"documentationSidebar"},"next-steps/gpu":{"id":"next-steps/gpu","title":"GPU Workloads","description":"Bacalhau supports GPU workloads. In this tutorial, learn how to run a job using GPU workloads with the Bacalhau client.","sidebar":"documentationSidebar"},"next-steps/networking":{"id":"next-steps/networking","title":"Accessing the Internet from Jobs","description":"By default, Bacalhau jobs do not have any access to the internet. This is to keep both compute providers and users safe from malicious activities.","sidebar":"documentationSidebar"},"next-steps/private-cluster":{"id":"next-steps/private-cluster","title":"Private Cluster","description":"It is possible to run Bacalhau completely disconnected from the main Bacalhau network so that you can run private workloads without risking running on public nodes or inadvertently sharing your data outside of your organization. The isolated network will not connect to the public Bacalhau network nor connect to a public network. To do this, we will run our network in-process rather than externally.","sidebar":"documentationSidebar"},"next-steps/update-checks":{"id":"next-steps/update-checks","title":"Automatic Update Checking","description":"Bacalhau has an update checking service to automatically detect whether a newer version of the software is available.","sidebar":"documentationSidebar"},"references/api/agent":{"id":"references/api/agent","title":"Agent API Documentation","description":"The Bacalhau Agent APIs provide a convenient means to retrieve information about the Bacalhau node you are communicating with, whether it serves as the orchestrator or functions as a compute node. These APIs offer valuable insights into the node\'s health, capabilities, and deployed Bacalhau version.","sidebar":"documentationSidebar"},"references/api/index":{"id":"references/api/index","title":"Bacalhau API Documentation","description":"Welcome to the official API documentation for Bacalhau. This guide provides a detailed insight into Bacalhau\'s RESTful HTTP APIs and demonstrates how to make the most out of them.","sidebar":"documentationSidebar"},"references/api/jobs":{"id":"references/api/jobs","title":"Jobs API Documentation","description":"Job APIs enables creating, managing, monitoring, and analyzing jobs in Bacalhau.","sidebar":"documentationSidebar"},"references/api/nodes":{"id":"references/api/nodes","title":"Nodes API Documentation","description":"Nodes API provides a way to query information about the nodes in the cluster.","sidebar":"documentationSidebar"},"references/cli/agent/alive/index":{"id":"references/cli/agent/alive/index","title":"Command: agent alive","description":"Description","sidebar":"documentationSidebar"},"references/cli/agent/index":{"id":"references/cli/agent/index","title":"command: agent","description":"Description","sidebar":"documentationSidebar"},"references/cli/agent/node/index":{"id":"references/cli/agent/node/index","title":"Command: agent node","description":"Description","sidebar":"documentationSidebar"},"references/cli/agent/version/index":{"id":"references/cli/agent/version/index","title":"Command: agent version","description":"The bacalhau agent version command is used to obtain the version of the bacalhau agent.","sidebar":"documentationSidebar"},"references/cli/index":{"id":"references/cli/index","title":"Commands CLI (Experimental)","description":"The following commands refer to experimental bacalhau cli version v1.1.0. Experimental means that the commands are not stable and may change in future versions. More stable commands, with limited functionality, are documented here.","sidebar":"documentationSidebar"},"references/cli/job/describe/index":{"id":"references/cli/job/describe/index","title":"Command: job describe","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/executions/index":{"id":"references/cli/job/executions/index","title":"Command: job executions","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/history/index":{"id":"references/cli/job/history/index","title":"Command: job history","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/index":{"id":"references/cli/job/index","title":"command: job","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/list/index":{"id":"references/cli/job/list/index","title":"Command: job list","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/logs/index":{"id":"references/cli/job/logs/index","title":"Command: job logs","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/run/index":{"id":"references/cli/job/run/index","title":"Command: job run","description":"Description","sidebar":"documentationSidebar"},"references/cli/job/stop/index":{"id":"references/cli/job/stop/index","title":"Command: job stop","description":"Description","sidebar":"documentationSidebar"},"references/cli/node/describe/index":{"id":"references/cli/node/describe/index","title":"Command: node describe","description":"The bacalhau node describe command offers users the ability to retrieve detailed information about a specific node using its unique identifier.","sidebar":"documentationSidebar"},"references/cli/node/index":{"id":"references/cli/node/index","title":"command: node","description":"Description","sidebar":"documentationSidebar"},"references/cli/node/list/index":{"id":"references/cli/node/list/index","title":"Command: node list","description":"The bacalhau node list command is designed to provide users with a comprehensive list of network nodes along with details based on specified flags.","sidebar":"documentationSidebar"},"references/job-specification/constraint":{"id":"references/job-specification/constraint","title":"Constraint Specification","description":"A Constraint represents a condition that must be met for a compute node to be eligible to run a given job. Operators have the flexibility to manually define node labels when initiating a node using the bacalhau serve command. Additionally, Bacalhau boasts features like automatic resource detection and dynamic labeling, further enhancing its capability.","sidebar":"documentationSidebar"},"references/job-specification/input-source":{"id":"references/job-specification/input-source","title":"InputSource Specification","description":"An InputSource defines where and how to retrieve specific artifacts needed for a Task, such as files or data, and where to mount them within the task\'s context. This ensures the necessary data is present before the task\'s execution begins.","sidebar":"documentationSidebar"},"references/job-specification/job":{"id":"references/job-specification/job","title":"Job Specification","description":"A Job represents a discrete unit of work that can be scheduled and executed. It carries all the necessary information to define the nature of the work, how it should be executed, and the resources it requires.","sidebar":"documentationSidebar"},"references/job-specification/label":{"id":"references/job-specification/label","title":"Labels Specification","description":"The Labels block within a Job specification plays a crucial role in Bacalhau, serving as a mechanism for filtering jobs. By attaching specific labels to jobs, users can quickly and effectively filter and manage jobs via both the Command Line Interface (CLI) and Application Programming Interface (API) based on various criteria.","sidebar":"documentationSidebar"},"references/job-specification/meta":{"id":"references/job-specification/meta","title":"Meta Specification","description":"In both the Job and Task specifications within Bacalhau, the Meta block is a versatile element used to attach arbitrary metadata. This metadata isn\'t utilized for filtering or categorizing jobs; there\'s a separate Labels block specifically designated for that purpose. Instead, the Meta block is instrumental for embedding additional information for operators or external systems, enhancing clarity and context.","sidebar":"documentationSidebar"},"references/job-specification/network":{"id":"references/job-specification/network","title":"Network Specification","description":"The Network object offers a method to specify the networking requirements of a Task. It defines the scope and constraints of the network connectivity based on the demands of the task.","sidebar":"documentationSidebar"},"references/job-specification/resources":{"id":"references/job-specification/resources","title":"Resources Specification","description":"The Resources provides a structured way to detail the computational resources a Task requires. By specifying these requirements, you ensure that the task is scheduled on a node with adequate resources, optimizing performance and avoiding potential issues linked to resource constraints.","sidebar":"documentationSidebar"},"references/job-specification/result-path":{"id":"references/job-specification/result-path","title":"ResultPath Specification","description":"A ResultPath denotes a specific location within a Task that contains meaningful output or results. By specifying a ResultPath, you can pinpoint which files or directories are essential and should be retained or published after the task\'s execution.","sidebar":"documentationSidebar"},"references/job-specification/spec-config":{"id":"references/job-specification/spec-config","title":"SpecConfig Specification","description":"SpecConfig provides a unified structure to specify configurations for various components in Bacalhau, including engines, publishers, and input sources. Its flexible design allows seamless integration with multiple systems like Docker, WebAssembly (Wasm), AWS S3, and local directories, among others.","sidebar":"documentationSidebar"},"references/job-specification/state":{"id":"references/job-specification/state","title":"state","description":"State Structure Specification","sidebar":"documentationSidebar"},"references/job-specification/task":{"id":"references/job-specification/task","title":"Task Specification","description":"A Task signifies a distinct unit of work within the broader context of a Job. It defines the specifics of how the task should be executed, where the results should be published, what environment variables are needed, among other configurations","sidebar":"documentationSidebar"},"references/job-specification/timeouts":{"id":"references/job-specification/timeouts","title":"Timeouts Specification","description":"The Timeouts object provides a mechanism to impose timing constraints on specific task operations, particularly execution. By setting these timeouts, users can ensure tasks don\'t run indefinitely and align them with intended durations.","sidebar":"documentationSidebar"},"references/other-specifications/engines/docker":{"id":"references/other-specifications/engines/docker","title":"Docker Engine Specification","description":"Docker Engine is one of the execution engines supported in Bacalhau. It allows users to run tasks inside Docker containers, offering an isolated and consistent environment for execution. Below are the parameters to configure the Docker Engine.","sidebar":"documentationSidebar"},"references/other-specifications/engines/wasm":{"id":"references/other-specifications/engines/wasm","title":"WebAssembly (WASM) Engine Specification","description":"The WASM Engine in Bacalhau allows tasks to be executed in a WebAssembly environment, offering compatibility and speed. This engine supports WASM and WASI (WebAssembly System Interface) jobs, making it highly adaptable for various use cases. Below are the parameters for configuring the WASM Engine.","sidebar":"documentationSidebar"},"references/other-specifications/publishers/ipfs":{"id":"references/other-specifications/publishers/ipfs","title":"IPFS Publisher Specification","description":"The IPFS Publisher in Bacalhau amplifies the versatility of task result storage by integrating with the InterPlanetary File System (IPFS). IPFS is a protocol and network designed to create a peer-to-peer method of storing and sharing hypermedia in a distributed file system. Bacalhau\'s seamless integration with IPFS ensures that users have a decentralized option for publishing their task results, enhancing accessibility and resilience while reducing dependence on a single point of failure.","sidebar":"documentationSidebar"},"references/other-specifications/publishers/s3":{"id":"references/other-specifications/publishers/s3","title":"S3 Publisher Specification","description":"Bacalhau\'s S3 Publisher provides users with a secure and efficient method to publish task results to any S3-compatible storage service. This publisher supports not just AWS S3, but other S3-compatible services offered by cloud providers like Google Cloud Storage and Azure Blob Storage, as well as open-source options like MinIO. The integration is designed to be highly flexible, ensuring users can choose the storage option that aligns with their needs, privacy preferences, and operational requirements.","sidebar":"documentationSidebar"},"references/other-specifications/sources/ipfs":{"id":"references/other-specifications/sources/ipfs","title":"IPFS Source Specification","description":"The IPFS Input Source enables users to easily integrate data hosted on the InterPlanetary File System (IPFS) into Bacalhau jobs. By specifying the Content Identifier (CID) of the desired IPFS file or directory, users can have the content fetched and made available in the task\'s execution environment, ensuring efficient and decentralized data access.","sidebar":"documentationSidebar"},"references/other-specifications/sources/local":{"id":"references/other-specifications/sources/local","title":"Local Source Specification","description":"The Local input source allows Bacalhau jobs to access files and directories that are already present on the compute node. This is especially useful for utilizing locally stored datasets, configuration files, logs, or other necessary resources without the need to fetch them from a remote source, ensuring faster job initialization and execution.","sidebar":"documentationSidebar"},"references/other-specifications/sources/s3":{"id":"references/other-specifications/sources/s3","title":"S3 Source Specification","description":"The S3 Input Source provides a seamless way to utilize data stored in S3 or any S3-compatible storage service as input for Bacalhau jobs. Users can specify files or entire prefixes stored in S3 buckets to be fetched and mounted directly into the task\'s execution environment. This capability ensures that your tasks have immediate access to the necessary data.","sidebar":"documentationSidebar"},"references/other-specifications/sources/url":{"id":"references/other-specifications/sources/url","title":"URL Source Specification","description":"The URL Input Source provides a straightforward method for Bacalhau jobs to access and incorporate data available over HTTP/HTTPS. By specifying a URL, users can ensure the required data, whether a single file or a web page content, is retrieved and prepared in the task\'s execution environment, enabling direct and efficient data utilization.","sidebar":"documentationSidebar"},"references/sdk/python-sdk":{"id":"references/sdk/python-sdk","title":"Bacalhau Python SDK :snake:","description":"This is the official Python SDK for Bacalhau, named bacalhau-sdk.","sidebar":"documentationSidebar"},"running-node/configuration":{"id":"running-node/configuration","title":"Configuration Overview","description":"How to configure your Bacalhau node.","sidebar":"documentationSidebar"},"running-node/configuring-tls":{"id":"running-node/configuring-tls","title":"Configuring Transport Level Security","description":"How to configure TLS for the requester node APIs","sidebar":"documentationSidebar"},"running-node/gpu":{"id":"running-node/gpu","title":"GPU Support","description":"How to enable GPU support on your Bacalhau node.","sidebar":"documentationSidebar"},"running-node/index":{"id":"running-node/index","title":"index","description":""},"running-node/job-selection":{"id":"running-node/job-selection","title":"Job selection policy","description":"When running a node, you can choose which jobs you want to run by using","sidebar":"documentationSidebar"},"running-node/networking":{"id":"running-node/networking","title":"Networking","description":"Bacalhau uses libp2p under the hood to communicate with other nodes on the network.","sidebar":"documentationSidebar"},"running-node/observability":{"id":"running-node/observability","title":"Observability","description":"Bacalhau supports the three main \'pillars\' of observability - logging, metrics, and tracing. Bacalhau uses the OpenTelemetry Go SDK for metrics and tracing, which can be configured using the standard environment variables. Exporting metrics and traces can be as simple as setting the OTELEXPORTEROTLPPROTOCOL and OTELEXPORTEROTLPENDPOINT environment variables. Custom code is used for logging as the OpenTelemetry Go SDK currently doesn\'t support logging.","sidebar":"documentationSidebar"},"running-node/persistence":{"id":"running-node/persistence","title":"Configuring node persistence","description":"How to configure compute/requester persistence","sidebar":"documentationSidebar"},"running-node/quick-start":{"id":"running-node/quick-start","title":"Join as Compute Provider","description":"Bacalhau is a peer-to-peer network of computing providers that will run jobs submitted by users. A Compute Provider (CP) is anyone who is running a Bacalhau compute node participating in the Bacalhau compute network, regardless of whether they are hosting any Filecoin data.","sidebar":"documentationSidebar"},"running-node/quick-start-docker":{"id":"running-node/quick-start-docker","title":"Running a Compute Node Using Docker","description":"Good news everyone! You can now run your Bacalhau-IPFS stack in Docker.","sidebar":"documentationSidebar"},"running-node/resource-limits":{"id":"running-node/resource-limits","title":"Resource Limits","description":"These are the flags that control the capacity of the Bacalhau node, and the limits for jobs that might be run.","sidebar":"documentationSidebar"},"running-node/storage-providers":{"id":"running-node/storage-providers","title":"Storage Providers","description":"Bacalhau has two ways to make use of external storage providers:","sidebar":"documentationSidebar"},"running-node/test-network":{"id":"running-node/test-network","title":"Test Network Locally","description":"Before you join the main Bacalhau network, you can test locally.","sidebar":"documentationSidebar"},"running-node/timeouts":{"id":"running-node/timeouts","title":"Job execution timeouts","description":"Bacalhau can limit the total time a job spends executing. A job that spends too","sidebar":"documentationSidebar"},"running-node/windows-support":{"id":"running-node/windows-support","title":"Windows support","description":"Running a Windows-based node is not officially supported, so your mileage may vary. Some features (like resource limits) are not present in Windows-based nodes.","sidebar":"documentationSidebar"},"topic-guides/index":{"id":"topic-guides/index","title":"Topic Guides","description":"Topic guides give a high level view of key topics and concepts, and provides useful background information and explanation of how Bacalhau works.","sidebar":"documentationSidebar"},"topic-guides/job-types":{"id":"topic-guides/job-types","title":"Job types","description":"The different job types available in Bacalhau","sidebar":"documentationSidebar"},"troubleshooting/debugging":{"id":"troubleshooting/debugging","title":"Debugging Failed Jobs","description":"How to troubleshoot and debug failed Bacalhau jobs","sidebar":"documentationSidebar"},"troubleshooting/faqs":{"id":"troubleshooting/faqs","title":"Bacalhau FAQs","description":"Can I use multiple data sources in the same job?","sidebar":"documentationSidebar"},"troubleshooting/index":{"id":"troubleshooting/index","title":"index","description":""}}}')}}]);