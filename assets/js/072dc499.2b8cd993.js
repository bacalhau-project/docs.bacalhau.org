"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[6508],{6502:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});var t=s(5893),r=s(1151);const o={sidebar_label:"Storage Providers",sidebar_position:130},a="Storage Providers",i={id:"running-node/storage-providers",title:"Storage Providers",description:"Bacalhau has two ways to make use of external storage providers:",source:"@site/docs/running-node/storage-providers.md",sourceDirName:"running-node",slug:"/running-node/storage-providers",permalink:"/running-node/storage-providers",draft:!1,unlisted:!1,editUrl:"https://github.com/bacalhau-project/docs.bacalhau.org/blob/main/docs/running-node/storage-providers.md",tags:[],version:"current",lastUpdatedAt:1700797095,formattedLastUpdatedAt:"Nov 24, 2023",sidebarPosition:130,frontMatter:{sidebar_label:"Storage Providers",sidebar_position:130},sidebar:"documentationSidebar",previous:{title:"Networking",permalink:"/running-node/networking"},next:{title:"Job Selection Policy",permalink:"/running-node/job-selection"}},d={},l=[{value:"Inputs",id:"inputs",level:2},{value:"IPFS",id:"ipfs",level:3},{value:"Publishers",id:"publishers",level:2},{value:"IPFS",id:"ipfs-1",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"storage-providers",children:"Storage Providers"}),"\n",(0,t.jsx)(n.p,{children:"Bacalhau has two ways to make use of external storage providers:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Inputs"})," storage resources consumed as inputs to jobs"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Publishers"})," storage resources created with the results of jobs"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"inputs",children:"Inputs"}),"\n",(0,t.jsx)(n.h3,{id:"ipfs",children:"IPFS"}),"\n",(0,t.jsx)(n.p,{children:"To start, you'll need to connect the Bacalhau node to an IPFS server so that you can run jobs that consume CIDs as inputs."}),"\n",(0,t.jsxs)(n.p,{children:["You can either ",(0,t.jsx)(n.a,{href:"https://docs.ipfs.tech/install/",children:"install IPFS"})," and run it locally, or you can connect to a remote IPFS server."]}),"\n",(0,t.jsxs)(n.p,{children:["In both cases, you should have an ",(0,t.jsx)(n.a,{href:"https://richardschneider.github.io/net-ipfs-core/articles/multiaddress.html",children:"IPFS multiaddress"})," for the IPFS server that should look something like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export IPFS_CONNECT=/ip4/10.1.10.10/tcp/80/p2p/QmVcSqVEsvm5RR9mBLjwpb2XjFVn5bPdPL69mL8PH45pPC\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsx)(n.p,{children:"The multiaddress above is just an example - you'll need to get the multiaddress of the IPFS server you want to connect to."})}),"\n",(0,t.jsxs)(n.p,{children:["You can then configure your Bacalhau node to use this IPFS server by passing the ",(0,t.jsx)(n.code,{children:"--ipfs-connect"})," argument to the ",(0,t.jsx)(n.code,{children:"serve"})," command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"bacalhau serve --ipfs-connect $IPFS_CONNECT\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Or, set the ",(0,t.jsx)(n.code,{children:"Node.IPFS.Connect"})," property in the Bacalhau configuration file."]}),"\n",(0,t.jsx)(n.h2,{id:"publishers",children:"Publishers"}),"\n",(0,t.jsx)(n.h3,{id:"ipfs-1",children:"IPFS"}),"\n",(0,t.jsxs)(n.p,{children:["The IPFS publisher works using the same setup as above - you'll need to have an\nIPFS server running and a multiaddress for it. You'll then you pass that\nmultiaddress using the ",(0,t.jsx)(n.code,{children:"--ipfs-connect"})," argument to the ",(0,t.jsx)(n.code,{children:"serve"})," command."]}),"\n",(0,t.jsxs)(n.p,{children:["If you are publishing to a public IPFS node, you can use ",(0,t.jsx)(n.code,{children:"bacalhau get"})," with no\nfurther arguments to download the results. However, you may experience a delay\nin results becoming available as indexing of new data by public nodes takes\ntime."]}),"\n",(0,t.jsxs)(n.p,{children:["To speed up the download or to retrieve results from a private IPFS node, pass\nthe swarm multiaddress to ",(0,t.jsx)(n.code,{children:"bacalhau get"})," to download results."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Set the below environment variable, use the --ipfs-swarm-addrs flag,\n# or set the Node.IPFS.SwarmAddresses config property.\nexport BACALHAU_IPFS_SWARM_ADDRESSES=/ip4/.../tcp/5001/p2p/Qmy...\nbacalhau get $JOB_ID\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Pass the swarm key to ",(0,t.jsx)(n.code,{children:"bacalhau get"})," if the IPFS swarm is a private swarm."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Set the below environment variable, use the --ipfs-swarm-key flag,\n# or set the Node.IPFS.SwarmKeyPath config property.\nexport BACALHAU_IPFS_SWARM_KEY=./path/to/swarm.key\nbacalhau get $JOB_ID\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},1151:(e,n,s)=>{s.d(n,{Z:()=>i,a:()=>a});var t=s(7294);const r={},o=t.createContext(r);function a(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);