"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[6796],{3905:(e,a,t)=>{t.d(a,{Zo:()=>d,kt:()=>m});var n=t(7294);function o(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){o(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,n,o=function(e,a){if(null==e)return{};var t,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(o[t]=e[t]);return o}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var c=n.createContext({}),s=function(e){var a=n.useContext(c),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},d=function(e){var a=s(e.components);return n.createElement(c.Provider,{value:a},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},b=n.forwardRef((function(e,a){var t=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=s(t),b=o,m=u["".concat(c,".").concat(b)]||u[b]||p[b]||r;return t?n.createElement(m,i(i({ref:a},d),{},{components:t})):n.createElement(m,i({ref:a},d))}));function m(e,a){var t=arguments,o=a&&a.mdxType;if("string"==typeof e||o){var r=t.length,i=new Array(r);i[0]=b;var l={};for(var c in a)hasOwnProperty.call(a,c)&&(l[c]=a[c]);l.originalType=e,l[u]="string"==typeof e?e:o,i[1]=l;for(var s=2;s<r;s++)i[s]=t[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}b.displayName="MDXCreateElement"},2565:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var n=t(7462),o=(t(7294),t(3905));const r={sidebar_label:"Python Pandas",sidebar_position:6},i="Running Pandas on Bacalhau",l={unversionedId:"examples/workload-onboarding/python-pandas/index",id:"examples/workload-onboarding/python-pandas/index",title:"Running Pandas on Bacalhau",description:"stars - badge-generator",source:"@site/docs/examples/workload-onboarding/python-pandas/index.md",sourceDirName:"examples/workload-onboarding/python-pandas",slug:"/examples/workload-onboarding/python-pandas/",permalink:"/examples/workload-onboarding/python-pandas/",draft:!1,editUrl:"https://github.com/bacalhau-project/docs.bacalhau.org/blob/main/docs/examples/workload-onboarding/python-pandas/index.md",tags:[],version:"current",lastUpdatedAt:1683114937,formattedLastUpdatedAt:"May 3, 2023",sidebarPosition:6,frontMatter:{sidebar_label:"Python Pandas",sidebar_position:6},sidebar:"documentationSidebar",previous:{title:"Python Custom Container",permalink:"/examples/workload-onboarding/Python-Custom-Container/"},next:{title:"R Custom Container",permalink:"/examples/workload-onboarding/r-custom-docker-prophet/"}},c={},s=[{value:"Introduction",id:"introduction",level:3},{value:"TD;LR",id:"tdlr",level:2},{value:"Prerequisite",id:"prerequisite",level:2},{value:"Running Pandas Locally",id:"running-pandas-locally",level:2},{value:"Importing data from CSV to DataFrame",id:"importing-data-from-csv-to-dataframe",level:3},{value:"Running the script",id:"running-the-script",level:3},{value:"Ingesting data",id:"ingesting-data",level:2},{value:"Running a Bacalhau Job",id:"running-a-bacalhau-job",level:2},{value:"Structure of the command",id:"structure-of-the-command",level:3},{value:"Checking the State of your Jobs",id:"checking-the-state-of-your-jobs",level:2},{value:"Viewing your Job Output",id:"viewing-your-job-output",level:2}],d={toc:s},u="wrapper";function p(e){let{components:a,...t}=e;return(0,o.kt)(u,(0,n.Z)({},d,t,{components:a,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"running-pandas-on-bacalhau"},"Running Pandas on Bacalhau"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/bacalhau-project/bacalhau"},(0,o.kt)("img",{parentName:"a",src:"https://img.shields.io/github/stars/bacalhau-project/bacalhau?style=social",alt:"stars - badge-generator"}))),(0,o.kt)("h3",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"Pandas is a Python package that provides fast, flexible, and expressive data structures designed to make working with data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis/manipulation tool available in any language. It is already well on its way towards this goal."),(0,o.kt)("h2",{id:"tdlr"},"TD;LR"),(0,o.kt)("p",null,"Running pandas script in Bacalhau"),(0,o.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("p",null,"To get started, you need to install the Bacalhau client, see more information ",(0,o.kt)("a",{parentName:"p",href:"https://docs.bacalhau.org/getting-started/installation"},"here")),(0,o.kt)("h2",{id:"running-pandas-locally"},"Running Pandas Locally"),(0,o.kt)("p",null,"To run Pandas script on Bacalhau for analysis, first we will place the Pandas script in a container and then run it at scale on Bacalhau. To get started, you need to install the Pandas library from pip."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\npip install pandas\n")),(0,o.kt)("h3",{id:"importing-data-from-csv-to-dataframe"},"Importing data from CSV to DataFrame"),(0,o.kt)("p",null,"Pandas is built around the idea of a DataFrame, a container for representing data. Below you will create a DataFrame by importing a CSV file. A CSV file is a text file with one record of data per line. The values within the record are separated using the \u201ccomma\u201d character. Pandas provides a useful method, named ",(0,o.kt)("inlineCode",{parentName:"p"},"read_csv()")," to read the contents of the CSV file into a DataFrame. For example, we can create a file named ",(0,o.kt)("inlineCode",{parentName:"p"},"transactions.csv")," containing details of Transactions. The CSV file is stored in the same directory that contains Python script."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'%%writefile read_csv.py\nimport pandas as pd\n\nprint(pd.read_csv("transactions.csv"))\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\n# Downloading the dataset\nwget https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/transactions.csv\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\ncat transactions.csv\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"hash,nonce,block_hash,block_number,transaction_index,from_address,to_address,value,gas,gas_price,input,block_timestamp,max_fee_per_gas,max_priority_fee_per_gas,transaction_type\n0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d897f1101eac3e3ad4fab8,12,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,0,0x1b63142628311395ceafeea5667e7c9026c862ca,0xf4eced2f682ce333f96f2d8966c613ded8fc95dd,0,150853,50000000000,0xa9059cbb000000000000000000000000ac4df82fe37ea2187bc8c011a23d743b4f39019a00000000000000000000000000000000000000000000000000000000000186a0,1446561880,,,0\n0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91bb7357de5421511cee49,84,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,1,0x9b22a80d5c7b3374a05b446081f97d0a34079e7f,0xf4eced2f682ce333f96f2d8966c613ded8fc95dd,0,150853,50000000000,0xa9059cbb00000000000000000000000066f183060253cfbe45beff1e6e7ebbe318c81e560000000000000000000000000000000000000000000000000000000000030d40,1446561880,,,0\n0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5eee598551697c297c235c,88,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,2,0x9df428a91ff0f3635c8f0ce752933b9788926804,0x9e669f970ec0f49bb735f20799a7e7c4a1c274e2,11000440000000000,90000,50000000000,0x,1446561880,,,0\n0x05287a561f218418892ab053adfb3d919860988b19458c570c5c30f51c146f02,20085,0x246edb4b351d93c27926f4649bcf6c24366e2a7c7c718dc9158eea20c03bc6ae,483920,3,0x2a65aca4d5fc5b5c859090a6c34d164135398226,0x743b8aeedc163c0e3a0fe9f3910d146c48e70da8,1530219620000000000,90000,50000000000,0x,1446561880,,,0\n")),(0,o.kt)("h3",{id:"running-the-script"},"Running the script"),(0,o.kt)("p",null,"Now let's run the script to read in the CSV file. The output will be a DataFrame object."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\npython3 read_csv.py\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"                                                hash  ...  transaction_type\n0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n\n[4 rows x 15 columns]\n")),(0,o.kt)("h2",{id:"ingesting-data"},"Ingesting data"),(0,o.kt)("p",null,"To run pandas on Bacalhau you must store your assets in a location that Bacalhau has access to. We usually default to storing data on IPFS and code in a container, but you can also easily upload your script to IPFS too."),(0,o.kt)("p",null,"If you are interested in finding out more about how to ingest your data into IPFS, please see the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.bacalhau.org/examples/data-ingestion/"},"data ingestion guide"),"."),(0,o.kt)("p",null,"We've already uploaded the script and data to IPFS to the following CID: ",(0,o.kt)("inlineCode",{parentName:"p"},"QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz"),". You can look at this by browsing to one of the HTTP IPFS proxies like ",(0,o.kt)("a",{parentName:"p",href:"https://cloudflare-ipfs.com/ipfs/QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz/"},"ipfs.io")," or ",(0,o.kt)("a",{parentName:"p",href:"https://bafybeih4hyydvojazlyv5zseelgn5u67iq2wbrbk2q4xoiw2d3cacdmzlu.ipfs.w3s.link/"},"w3s.link"),"."),(0,o.kt)("h2",{id:"running-a-bacalhau-job"},"Running a Bacalhau Job"),(0,o.kt)("p",null,"After mounting the Pandas script and data from IPFS, we can now use the container for running on Bacalhau. To submit a job, run the following Bacalhau command:"),(0,o.kt)("p",null,"Now we're ready to run a Bacalhau job, whilst mounting the Pandas script and data from IPFS. We'll use the ",(0,o.kt)("inlineCode",{parentName:"p"},"bacalhau docker run")," command to do this. The ",(0,o.kt)("inlineCode",{parentName:"p"},"-v")," flag allows us to mount a file or directory from IPFS into the container. The ",(0,o.kt)("inlineCode",{parentName:"p"},"-v")," flag takes two arguments, the first is the IPFS CID and the second is the path to the directory in the container. The ",(0,o.kt)("inlineCode",{parentName:"p"},"-v")," flag can be used multiple times to mount multiple directories."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash --out job_id\nbacalhau docker run \\\n    --wait \\\n    --id-only \\\n    -i ipfs://QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz:/files \\\n    -w /files \\\n    amancevice/pandas \\\n    -- python read_csv.py\n")),(0,o.kt)("h3",{id:"structure-of-the-command"},"Structure of the command"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"bacalhau docker run"),": call to bacalhau ")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"amancevice/pandas "),": Using the official pytorch Docker image")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"`",(0,o.kt)("inlineCode",{parentName:"p"},"-i ipfs://QmfKJT13h5k1b23ja3Z ....."),": Mounting the uploaded dataset to path")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"-w /files")," Our working directory is /outputs. This is the folder where we will to save the model as it will automatically gets uploaded to IPFS as outputs"))),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"}," python read_csv.py"),": python script to read pandas script"),(0,o.kt)("p",null,"When a job is submitted, Bacalhau prints out the related ",(0,o.kt)("inlineCode",{parentName:"p"},"job_id"),". We store that in an environment variable so that we can reuse it later on."),(0,o.kt)("h2",{id:"checking-the-state-of-your-jobs"},"Checking the State of your Jobs"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Job status"),": You can check the status of the job using ",(0,o.kt)("inlineCode",{parentName:"li"},"bacalhau list"),". ")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\nbacalhau list --id-filter ${JOB_ID}\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\x1b[92;100m CREATED  \x1b[0m\x1b[92;100m ID       \x1b[0m\x1b[92;100m JOB                     \x1b[0m\x1b[92;100m STATE     \x1b[0m\x1b[92;100m VERIFIED \x1b[0m\x1b[92;100m PUBLISHED               \x1b[0m\n\x1b[97;40m 11:46:26 \x1b[0m\x1b[97;40m 61e542a7 \x1b[0m\x1b[97;40m Docker amancevice/pa... \x1b[0m\x1b[97;40m Completed \x1b[0m\x1b[97;40m          \x1b[0m\x1b[97;40m ipfs://QmY2MEETWyX77... \x1b[0m\n")),(0,o.kt)("p",null,"When it says ",(0,o.kt)("inlineCode",{parentName:"p"},"Completed"),", that means the job is done, and we can get the results."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Job information"),": You can find out more information about your job by using ",(0,o.kt)("inlineCode",{parentName:"li"},"bacalhau describe"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\nbacalhau describe ${JOB_ID}\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'Job:\n  APIVersion: V1beta1\n  Metadata:\n    ClientID: 07bde6e8241b19d58c1c5ff3e8ec17e1e80ac6424cd029bd1317a60f1705b583\n    CreatedAt: "2023-05-03T11:46:26.767484787Z"\n    ID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n    Requester:\n      RequesterNodeID: QmdZQ7ZbhnvWY1J12XYKGHApJ6aufKyLNSvf8jZBrBaAVL\n      RequesterPublicKey: CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVRKPgCfY2fgfrkHkFjeWcqno+MDpmp8DgVaY672BqJl/dZFNU9lBg2P8Znh8OTtHPPBUBk566vU3KchjW7m3uK4OudXrYEfSfEPnCGmL6GuLiZjLf+eXGEez7qPaoYqo06gD8ROdD8VVse27E96LlrpD1xKshHhqQTxKoq1y6Rx4DpbkSt966BumovWJ70w+Nt9ZkPPydRCxVnyWS1khECFQxp5Ep3NbbKtxHNX5HeULzXN5q0EQO39UN6iBhiI34eZkH7PoAm3Vk5xns//FjTAvQw6wZUu8LwvZTaihs+upx2zZysq6CEBKoeNZqed9+Tf+qHow0P5pxmiu+or+DAgMBAAE=\n  Spec:\n    Deal:\n      Concurrency: 1\n    Docker:\n      Entrypoint:\n      - python\n      - read_csv.py\n      Image: amancevice/pandas\n      WorkingDirectory: /files\n    Engine: Docker\n    Language:\n      JobContext: {}\n    Network:\n      Type: None\n    Publisher: Estuary\n    PublisherSpec:\n      Type: Estuary\n    Resources:\n      GPU: ""\n    Timeout: 1800\n    Verifier: Noop\n    Wasm:\n      EntryModule: {}\n    inputs:\n    - CID: QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz\n      Name: ipfs://QmfKJT13h5k1b23ja3ZCVg5nFL9oKz2bVXc8oXgtwiwhjz\n      StorageSource: IPFS\n      path: /files\n    outputs:\n    - Name: outputs\n      StorageSource: IPFS\n      path: /outputs\nState:\n  CreateTime: "2023-05-03T11:46:26.767504591Z"\n  Executions:\n  - AcceptedAskForBid: true\n    ComputeReference: e-37a9de63-8bf2-4d83-932f-29fdf98c5274\n    CreateTime: "2023-05-03T11:46:35.551431968Z"\n    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n    NodeId: QmYgxZiySj3MRkwLSL4X2MF5F9f2PMhAE3LV49XkfNL1o3\n    PublishedResults:\n      CID: QmY2MEETWyX77BBYBNBpUW5bjkVAyP87EotPDVW2vjHG8K\n      Name: ipfs://QmY2MEETWyX77BBYBNBpUW5bjkVAyP87EotPDVW2vjHG8K\n      StorageSource: IPFS\n    RunOutput:\n      exitCode: 0\n      runnerError: ""\n      stderr: ""\n      stderrtruncated: false\n      stdout: |2\n                                                        hash  ...  transaction_type\n        0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n        1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n        2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n        3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n\n        [4 rows x 15 columns]\n      stdouttruncated: false\n    State: Completed\n    UpdateTime: "2023-05-03T11:46:35.543450963Z"\n    VerificationResult:\n      Complete: true\n      Result: true\n    Version: 6\n  - AcceptedAskForBid: true\n    ComputeReference: e-1f8a0747-bf6d-49c2-973c-35dfb957448b\n    CreateTime: "2023-05-03T11:46:27.267720744Z"\n    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n    NodeId: QmXaXu9N5GNetatsvwnTfQqNtSeKAD6uCmarbh3LMRYAcF\n    PublishedResults: {}\n    State: BidRejected\n    UpdateTime: "2023-05-03T11:46:27.267494495Z"\n    VerificationResult: {}\n    Version: 3\n  - AcceptedAskForBid: true\n    ComputeReference: e-8c1c582c-9994-4f87-ba57-746965532790\n    CreateTime: "2023-05-03T11:46:28.584477348Z"\n    JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n    NodeId: QmUDAXvv31WPZ8U9CzuRTMn9iFGiopGE7rHiah1X8a6PkT\n    PublishedResults: {}\n    State: BidRejected\n    UpdateTime: "2023-05-03T11:46:28.5840629Z"\n    VerificationResult: {}\n    Version: 3\n  JobID: 61e542a7-bea1-4382-b3c9-40050d143ad6\n  State: Completed\n  TimeoutAt: "0001-01-01T00:00:00Z"\n  UpdateTime: "2023-05-03T11:46:35.551464593Z"\n  Version: 5\n')),(0,o.kt)("p",null,"When it says ",(0,o.kt)("inlineCode",{parentName:"p"},"Published")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"Completed"),", that means the job is done, and we can get the results."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Job information"),": You can find out more information about your job by using ",(0,o.kt)("inlineCode",{parentName:"li"},"bacalhau describe"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\nrm -rf results && mkdir -p results\nbacalhau get ${JOB_ID}  --output-dir results\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"Fetching results of job '61e542a7-bea1-4382-b3c9-40050d143ad6'...\n\nComputing default go-libp2p Resource Manager limits based on:\n    - 'Swarm.ResourceMgr.MaxMemory': \"34 GB\"\n    - 'Swarm.ResourceMgr.MaxFileDescriptors': 524288\n\nApplying any user-supplied overrides on top.\nRun 'ipfs swarm limit all' to see the resulting limits.\n\nResults for job '61e542a7-bea1-4382-b3c9-40050d143ad6' have been written to...\nresults\n")),(0,o.kt)("h2",{id:"viewing-your-job-output"},"Viewing your Job Output"),(0,o.kt)("p",null,"Each job creates 3 subfolders: the ",(0,o.kt)("strong",{parentName:"p"},"combined_results"),",",(0,o.kt)("strong",{parentName:"p"},"per_shard files"),", and the ",(0,o.kt)("strong",{parentName:"p"},"raw")," directory. To view the file, run the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"%%bash\ncat results/stdout # displays the contents of the file\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"                                                hash  ...  transaction_type\n0  0x04cbcb236043d8fb7839e07bbc7f5eed692fb2ca55d8...  ...                 0\n1  0xcea6f89720cc1d2f46cc7a935463ae0b99dd5fad9c91...  ...                 0\n2  0x463d53f0ad57677a3b430a007c1c31d15d62c37fab5e...  ...                 0\n3  0x05287a561f218418892ab053adfb3d919860988b1945...  ...                 0\n\n[4 rows x 15 columns]\n")))}p.isMDXComponent=!0}}]);