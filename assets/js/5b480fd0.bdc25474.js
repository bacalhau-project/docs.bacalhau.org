"use strict";(self.webpackChunkbacalhau_docs=self.webpackChunkbacalhau_docs||[]).push([[3869],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>m});var a=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),u=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},c=function(e){var n=u(e.components);return a.createElement(s.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,l=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=u(t),m=o,h=p["".concat(s,".").concat(m)]||p[m]||d[m]||l;return t?a.createElement(h,r(r({ref:n},c),{},{components:t})):a.createElement(h,r({ref:n},c))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var l=t.length,r=new Array(l);r[0]=p;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i.mdxType="string"==typeof e?e:o,r[1]=i;for(var u=2;u<l;u++)r[u]=t[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},1209:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>u});var a=t(7462),o=(t(7294),t(3905));const l={sidebar_label:"CUDA",sidebar_position:10},r="Run CUDA programs on bacalhau",i={unversionedId:"examples/workload-onboarding/CUDA/index",id:"examples/workload-onboarding/CUDA/index",title:"Run CUDA programs on bacalhau",description:"Open In Colab",source:"@site/docs/examples/workload-onboarding/CUDA/index.md",sourceDirName:"examples/workload-onboarding/CUDA",slug:"/examples/workload-onboarding/CUDA/",permalink:"/examples/workload-onboarding/CUDA/",draft:!1,editUrl:"https://github.com/bacalhau-project/docs.bacalhau.org/blob/main/docs/examples/workload-onboarding/CUDA/index.md",tags:[],version:"current",lastUpdatedAt:1676428923,formattedLastUpdatedAt:"Feb 15, 2023",sidebarPosition:10,frontMatter:{sidebar_label:"CUDA",sidebar_position:10},sidebar:"documentationSidebar",previous:{title:"Python-Custom-Container",permalink:"/examples/workload-onboarding/Python-Custom-Container/"},next:{title:"Prolog-Hello-World",permalink:"/examples/workload-onboarding/Prolog-Hello-World/"}},s={},u=[{value:"Introduction",id:"introduction",level:2},{value:"What is CUDA",id:"what-is-cuda",level:3},{value:"Advantage of GPU over CPU",id:"advantage-of-gpu-over-cpu",level:3},{value:"Running locally",id:"running-locally",level:2},{value:"Viewing the programs",id:"viewing-the-programs",level:3},{value:"Running on bacalhau",id:"running-on-bacalhau",level:2}],c={toc:u};function d(e){let{components:n,...t}=e;return(0,o.kt)("wrapper",(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"run-cuda-programs-on-bacalhau"},"Run CUDA programs on bacalhau"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://colab.research.google.com/github/bacalhau-project/examples/blob/main/workload-onboarding/CUDA/index.ipynb"},(0,o.kt)("img",{parentName:"a",src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})),"\n",(0,o.kt)("a",{parentName:"p",href:"https://mybinder.org/v2/gh/bacalhau-project/examples/HEAD?labpath=workload-onboarding/CUDA/index.ipynb"},(0,o.kt)("img",{parentName:"a",src:"https://mybinder.org/badge.svg",alt:"Open In Binder"}))),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("h3",{id:"what-is-cuda"},"What is CUDA"),(0,o.kt)("p",null,"CUDA stands for Compute Unified Device Architecture. It is an extension of C/C++ programming."),(0,o.kt)("p",null,"CUDA is a parallel computing platform and programming model created by NVIDIA.\nit helps developers speed up their applications by harnessing the power of GPU accelerators."),(0,o.kt)("p",null,"In addition to accelerating high performance computing (HPC) and research applications, CUDA has also been widely adopted across consumer and industrial ecosystems."),(0,o.kt)("p",null,"CUDA also makes it easy for developers to take advantage of all the latest GPU architecture innovations"),(0,o.kt)("h3",{id:"advantage-of-gpu-over-cpu"},"Advantage of GPU over CPU"),(0,o.kt)("p",null,"Architecturally, the CPU is composed of just a few cores with lots of cache memory that can handle a few software threads at a time. In contrast, a GPU is composed of hundreds of cores that can handle thousands of threads simultaneously."),(0,o.kt)("p",null,"Computations like matrix multiplication could be done much faster on GPU than on CPU"),(0,o.kt)("h2",{id:"running-locally"},"Running locally"),(0,o.kt)("p",null,"Prerequisites"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"NVIDIA GPU"),(0,o.kt)("li",{parentName:"ul"},"CUDA drivers installed"),(0,o.kt)("li",{parentName:"ul"},"nvcc installed")),(0,o.kt)("p",null,"checking if nvcc is installed"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"!nvcc --version\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2021 NVIDIA Corporation\nBuilt on Sun_Feb_14_21:12:58_PST_2021\nCuda compilation tools, release 11.2, V11.2.152\nBuild cuda_11.2.r11.2/compiler.29618528_0\n")),(0,o.kt)("p",null,"Downloading the programs"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir inputs outputs\nwget -P inputs https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/00-hello-world.cu\nwget -P inputs https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"--2022-11-14 10:12:12--  https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/00-hello-world.cu\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 517 [text/plain]\nSaving to: \u2018inputs/00-hello-world.cu\u2019\n\n     0K                                                       100% 21.5M=0s\n\n2022-11-14 10:12:12 (21.5 MB/s) - \u2018inputs/00-hello-world.cu\u2019 saved [517/517]\n\n--2022-11-14 10:12:12--  https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1231 (1.2K) [text/plain]\nSaving to: \u2018inputs/02-cuda-hello-world-faster.cu\u2019\n\n     0K .                                                     100% 49.1M=0s\n\n2022-11-14 10:12:12 (49.1 MB/s) - \u2018inputs/02-cuda-hello-world-faster.cu\u2019 saved [1231/1231]\n")),(0,o.kt)("h3",{id:"viewing-the-programs"},"Viewing the programs"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat inputs/00-hello-world.cu\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'#include <cmath>\n#include <iostream>\n#include <vector>\n\nint main()\n{\n    size_t n = 50000000;\n    std::vector<double> a(n);\n    std::vector<double> b(n);\n    for (int i = 0; i < n; i++) {\n        a[i] = sin(i) * sin(i);\n        b[i] = cos(i) * cos(i);\n    }\n\n    std::vector<double> c(n);\n    for (int i = 0; i < n; i++) {\n        c[i] = a[i] + b[i];\n    }\n\n    double sum = 0;\n    for (int i = 0; i < n; i++) {\n        sum += c[i];\n    }\n\n    std::cout << "final result " << (sum / n) << std::endl;\n\n    return 0;\n}\n')),(0,o.kt)("p",null,"This is a standard c++ program which uses loops which are not parallizable so it dosen't use the most of the processing power of the GPU"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"%%timeit\n!nvcc -o ./outputs/hello ./inputs/00-hello-world.cu; ./outputs/hello\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"final result 1\nfinal result 1\nfinal result 1\nfinal result 1\nfinal result 1\nfinal result 1\nfinal result 1\nfinal result 1\n8.6 s \xb1 72.6 ms per loop (mean \xb1 std. dev. of 7 runs, 1 loop each)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"!cat inputs/02-cuda-hello-world-faster.cu\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n__global__ void prepData(double *a, double *b, size_t n)\n{\n    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < n) {\n        a[idx] = sin(idx) * sin(idx);\n        b[idx] = cos(idx) * cos(idx);\n    }\n}\n\n__global__ void vecAdd(double *a, double *b, double *c, size_t n)\n{\n    const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < n) {\n        c[idx] = a[idx] + b[idx];\n    }\n}\n\nint main()\n{\n    size_t n = 50000000;\n    size_t bytes = n * sizeof(double);\n    double *h_c = (double *) malloc(bytes);  // output vector\n\n    double *d_a, *d_b, *d_c;\n    cudaMalloc(&d_a, bytes);\n    cudaMalloc(&d_b, bytes);\n    cudaMalloc(&d_c, bytes);\n\n    const int blockSize = 1024;\n    const int gridSize = (int)ceil((float)n/blockSize);\n\n    prepData<<<gridSize, blockSize>>>(d_a, d_b, n);\n\n    cudaDeviceSynchronize();\n\n    vecAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n\n    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n\n    double sum = 0;\n    for (int i = 0; i < n; i++) {\n        sum += h_c[i];\n    }\n\n    printf("final result: %f\\n", sum / n);\n\n    cudaFree(d_a);\n    cudaFree(d_b);\n    cudaFree(d_c);\n\n    free(h_c);\n\n    return 0;\n}\n')),(0,o.kt)("p",null,"Instead of looping we use Vector addition using CUDA and allocate the memory in advance and copy the memory to the GPU\nusing cudaMemcpy so that it can utilize the HBM (High Bandwith memory of the GPU)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"!rm -rf outputs/hello\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"%%timeit\n!nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"final result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\nfinal result: 1.000000\n1.48 s \xb1 46.6 ms per loop (mean \xb1 std. dev. of 7 runs, 1 loop each)\n")),(0,o.kt)("p",null,"It takes around 8.67s to run\n00-hello-world.cu\nwhile it takes 1.39s to run\n02-cuda-hello-world-faster.cu"),(0,o.kt)("h2",{id:"running-on-bacalhau"},"Running on bacalhau"),(0,o.kt)("p",null,"Installing bacalhau"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"curl -sL https://get.bacalhau.org/install.sh | bash\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"Your system is linux_amd64\nNo BACALHAU detected. Installing fresh BACALHAU CLI...\nGetting the latest BACALHAU CLI...\nInstalling v0.3.11 BACALHAU CLI...\nDownloading https://github.com/filecoin-project/bacalhau/releases/download/v0.3.11/bacalhau_v0.3.11_linux_amd64.tar.gz ...\nDownloading sig file https://github.com/filecoin-project/bacalhau/releases/download/v0.3.11/bacalhau_v0.3.11_linux_amd64.tar.gz.signature.sha256 ...\nVerified OK\nExtracting tarball ...\nNOT verifying Bin\nbacalhau installed into /usr/local/bin successfully.\nClient Version: v0.3.11\nServer Version: v0.3.11\n")),(0,o.kt)("p",null,"You can easily execute the same program we ran locally using bacalhau"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The program is mounted by using the ",(0,o.kt)("inlineCode",{parentName:"li"},"-u")," flag you can specify the link there\n",(0,o.kt)("inlineCode",{parentName:"li"},"-u < Link-To-The-Program >"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Docker container ",(0,o.kt)("inlineCode",{parentName:"p"},"nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04"),"\nfor executing CUDA programs you need to choose the right CUDA docker container the container should have the tag of devel in them")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Running program consists of two parts:"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Compilation using the nvcc compiler and save it to the outputs directory as hello: ",(0,o.kt)("inlineCode",{parentName:"li"},"nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu")),(0,o.kt)("li",{parentName:"ul"},"Execution hello binary:  ",(0,o.kt)("inlineCode",{parentName:"li"},"./outputs/hello")),(0,o.kt)("li",{parentName:"ul"},"You can combine compilation and execution commands. Note that there is ",(0,o.kt)("inlineCode",{parentName:"li"},";")," between the commands:\n",(0,o.kt)("inlineCode",{parentName:"li"},"-- /bin/bash -c 'nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello "))))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"}," bacalhau docker run \\\n--gpu 1 \\\n--timeout 3600 \\\n--wait-timeout-secs 3600 \\\n -u https://raw.githubusercontent.com/tristanpenman/cuda-examples/master/02-cuda-hello-world-faster.cu \\\n --id-only \\\n --wait \\\n nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04 \\\n-- /bin/bash -c 'nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello '\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"bacalhau list --id-filter ${JOB_ID} --wide\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\x1b[92;100m CREATED           \x1b[0m\x1b[92;100m ID                                   \x1b[0m\x1b[92;100m JOB                                                                                                                                                                        \x1b[0m\x1b[92;100m STATE     \x1b[0m\x1b[92;100m VERIFIED \x1b[0m\x1b[92;100m PUBLISHED                                            \x1b[0m\n\x1b[97;40m 22-11-14-12:31:45 \x1b[0m\x1b[97;40m 22715ef6-759e-488a-9aa3-aaf2c8a79b08 \x1b[0m\x1b[97;40m Docker nvidia/cuda:11.2.0-cudnn8-devel-ubuntu18.04 /bin/bash -c nvcc --expt-relaxed-constexpr  -o ./outputs/hello ./inputs/02-cuda-hello-world-faster.cu; ./outputs/hello  \x1b[0m\x1b[97;40m Completed \x1b[0m\x1b[97;40m          \x1b[0m\x1b[97;40m /ipfs/QmSFnLwaCdoVGpyfjFZDpQ72AS5hTgzzCKmfznnVrH8SgH \x1b[0m\n")),(0,o.kt)("p",null,'Where it says "Completed", that means the job is done, and we can get the results.'),(0,o.kt)("p",null,"To find out more information about your job, run the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"bacalhau describe ${JOB_ID}\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"rm -rf results && mkdir -p results\nbacalhau get $JOB_ID --output-dir results\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"Fetching results of job '22715ef6-759e-488a-9aa3-aaf2c8a79b08'...\nResults for job '22715ef6-759e-488a-9aa3-aaf2c8a79b08' have been written to...\nresults\n\n\n2022/11/14 12:32:02 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.\n")),(0,o.kt)("p",null,"Viewing the outputs"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat results/combined_results/stdout\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"final result: 1.000000\n")))}d.isMDXComponent=!0}}]);